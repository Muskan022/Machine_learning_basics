{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee9a29ed",
   "metadata": {},
   "source": [
    "### Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its  application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98f20d",
   "metadata": {},
   "source": [
    "ANs - \n",
    "Min-Max scaling is a data preprocessing technique that adjusts the values of features in a dataset to a common range, typically between 0 and 1. It's useful for preventing features with larger values from dominating the learning process in machine learning algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baca42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df = sns.load_dataset(\"tips\")\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c777098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e55388a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(df[[\"total_bill\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8117562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_bill'] = pd.DataFrame(scaler.transform(df[[\"total_bill\"]]))## values are scaled between 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9482ae0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.291579</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.152283</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.375786</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.431713</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.450775</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0    0.291579  1.01  Female     No  Sun  Dinner     2\n",
       "1    0.152283  1.66    Male     No  Sun  Dinner     3\n",
       "2    0.375786  3.50    Male     No  Sun  Dinner     3\n",
       "3    0.431713  3.31    Male     No  Sun  Dinner     2\n",
       "4    0.450775  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() ## df with scaled value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a8b839",
   "metadata": {},
   "source": [
    "### Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?  Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23aa47",
   "metadata": {},
   "source": [
    "Ans - The Unit Vector technique, also known as Normalization, is another method for feature scaling in data preprocessing. Unlike Min-Max scaling that scales features to a specific range (e.g., 0 to 1), Normalization scales each feature in a way that the entire feature vector (row of data) has a length of 1 (i.e., it transforms the data into a unit vector). This technique is particularly useful when you want to ensure that the magnitude of the feature vector doesn't dominate the learning process, regardless of the original range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c8023e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m columns \u001b[38;5;241m=\u001b[39m titanic[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Normalize the columns using sklearn's normalize function\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m normalized_columns \u001b[38;5;241m=\u001b[39m normalize(columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalize' is not defined"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'fare': [50.0, 20.0, 100.0, 30.0],\n",
    "    'age': [25, 30, 22, 35]\n",
    "}\n",
    "titanic = pd.DataFrame(data)\n",
    "\n",
    "# Extract the \"fare\" and \"age\" columns\n",
    "columns = titanic[['fare', 'age']].values\n",
    "\n",
    "# Normalize the columns using sklearn's normalize function\n",
    "normalized_columns = normalize(columns, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d766336",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5813a05d",
   "metadata": {},
   "source": [
    "### Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an  example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de964a",
   "metadata": {},
   "source": [
    "Ans - Principal Component Analysis (PCA) is a technique for reducing the dimensionality of a dataset while retaining important information. It involves finding new directions (principal components) in the data that capture the most variance.\n",
    "\n",
    "here are the steps required:\n",
    "\n",
    "1. Center the data.\n",
    "2. Compute covariance matrix.\n",
    "3. Find eigenvectors and eigenvalues.\n",
    "4. Select top eigenvector (principal component).\n",
    "5. Project data onto the principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93fbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "data = np.array([[5, 10],\n",
    "                 [10, 15],\n",
    "                 [2, 4],\n",
    "                 [15, 30]])\n",
    "\n",
    "# Create a PCA\n",
    "pca = PCA(n_components=1)\n",
    "\n",
    "# Fit the PCA model to the data and transform the data to the new space\n",
    "reduced_data = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data ## reduced to one dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34fa867",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature  Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c077c",
   "metadata": {},
   "source": [
    "###### Relationship between PCA and Feature Extraction \n",
    "\n",
    "PCA (Principal Component Analysis) is closely related to Feature Extraction, as both techniques involve transforming the original features of a dataset into a new set of features. The key difference lies in the goal: PCA aims to capture maximum variance in the data, while feature extraction focuses on creating new features that represent the data in a way that is more informative or discriminative for a specific task.\n",
    "\n",
    "###### Use of PCA to extract features\n",
    "\n",
    "PCA can be used as a feature extraction technique when you want to reduce the dimensionality of your dataset while preserving as much information as possible. It involves selecting a subset of the most important principal components (new features) to represent the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create synthetic data with features representing pixel values\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(100, 784)  # 100 images with 28x28 pixels each\n",
    "\n",
    "# Apply PCA for feature extraction\n",
    "pca = PCA(n_components=50)\n",
    "reduced_data = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c857da2",
   "metadata": {},
   "source": [
    "### Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset  contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to  preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c310ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first generate a data \n",
    "df = pd.DataFrame({\n",
    "    'price': [10.0, 20.0, 15.0, 25.0, 30.0],\n",
    "    'rating': [4.2, 3.8, 4.5, 4.0, 3.7],\n",
    "    'delivery_time': [30, 45, 25, 50, 40]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3698ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() \n",
    "scaled_Data = scaler.fit_transform(df) ## transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97386c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(scaled_Data, columns=['price','rating','delivery_time'])\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26aab5",
   "metadata": {},
   "source": [
    "### Q6. You are working on a project to build a model to predict stock prices. The dataset contains many  features, such as company financial data and market trends. Explain how you would use PCA to reduce the  dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347ab1b",
   "metadata": {},
   "source": [
    "Ans - \n",
    "###### Steps to use PCA to reduce the  dimensionality of the dataset.\n",
    "\n",
    "1. Data Collection: Gather a dataset containing various features related to company financial data and market trends.\n",
    "\n",
    "2. Data Preprocessing: Clean and preprocess the data, including handling missing values and scaling.\n",
    "\n",
    "3. Apply PCA: Instantiate a PCA model, specifying the desired number of components or explained variance. Fit the PCA model on the preprocessed data.\n",
    "\n",
    "4. Explained Variance Ratio: Check the explained variance ratio of each principal component to understand their importance in capturing the data's variance. Decide how many components to keep based on cumulative explained variance.\n",
    "\n",
    "5.  Data: Transform the original data using the fitted PCA model to obtain lower-dimensional representations.\n",
    "\n",
    "6. Modeling: Split the transformed data into training and testing sets. Train a stock price prediction model (e.g., Linear Regression, Random Forest) on the reduced data.\n",
    "\n",
    "7. Evaluation and Interpretation: Make predictions using the trained model.Evaluate the model's performance using appropriate metrics (e.g., Mean Squared Error). Interpret the model's predictions and insights to inform trading decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6bcfd6",
   "metadata": {},
   "source": [
    "### Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the  values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A =np.array([[1,5,10,15,20]]).T\n",
    "scaler = MinMaxScaler(feature_range =(-1,1)) \n",
    "scaler.fit(A)\n",
    "new_A = scaler.transform(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b13c6",
   "metadata": {},
   "source": [
    "### Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform  Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ebb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.random.rand(100,5),columns =['height', 'weight', 'age', 'gender', 'blood pressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24117c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "# It calculates the cumulative variance ratio of the principal components. \n",
    "num_components_to_retain = np.argmax(cumulative_variance_ratio >= 0.95) + 1  \n",
    "## since python uses zero-based indexing, we need to add 1 to get the actual number of components\n",
    "\n",
    "# Transform the data using the chosen number of components\n",
    "reduced_data = pca.transform(data)[:, :num_components_to_retain]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c59c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_components_to_retain) ## retained all the 5 fetaures\n",
    "print(reduced_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d400a8d1",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
